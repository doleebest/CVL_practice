{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to apply to Video! </br>\n",
    "the next step would be to analyze these for the whole video. </br>\n",
    "So keep the background image, load every new frame of the video, run your calculations, and then save it to a video file. This tutorial might be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error opening the video file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"Resources/Cars.mp4\"\n"
     ]
    }
   ],
   "source": [
    "# example codes\n",
    "# reference : https://learnopencv.com/reading-and-writing-videos-using-opencv/\n",
    "import cv2 \n",
    " \n",
    "# Create a video capture object, in this case we are reading the video from a file\n",
    "vid_capture = cv2.VideoCapture('Resources/Cars.mp4')\n",
    " \n",
    "if (vid_capture.isOpened() == False):\n",
    "  print(\"Error opening the video file\")\n",
    "# Read fps and frame count\n",
    "else:\n",
    "  # Get frame rate information\n",
    "  # You can replace 5 with CAP_PROP_FPS as well, they are enumerations\n",
    "  fps = vid_capture.get(5)\n",
    "  print('Frames per second : ', fps,'FPS')\n",
    " \n",
    "  # Get frame count\n",
    "  # You can replace 7 with CAP_PROP_FRAME_COUNT as well, they are enumerations\n",
    "  frame_count = vid_capture.get(7)\n",
    "  print('Frame count : ', frame_count)\n",
    " \n",
    "while(vid_capture.isOpened()):\n",
    "  # vid_capture.read() methods returns a tuple, first element is a bool \n",
    "  # and the second is frame\n",
    "  ret, frame = vid_capture.read()\n",
    "  if ret == True:\n",
    "    cv2.imshow('Frame',frame)\n",
    "    # 20 is in milliseconds, try to increase the value, say 50 and observe\n",
    "    key = cv2.waitKey(20)\n",
    "     \n",
    "    if key == ord('q'):\n",
    "      break\n",
    "  else:\n",
    "    break\n",
    " \n",
    "# Release the video capture object\n",
    "vid_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "color_filenames = os.listdir(\"color\")\n",
    "depth_filenames = os.listdir(\"depth\")\n",
    "\n",
    "background_depth = cv2.imread(depth_filenames[0])\n",
    "\n",
    "output_filename = 'output_video.avi'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID') # 비디오 코덱을 지정하는 4자 코드\n",
    "fps = 25.0 # 초당 프레임 수\n",
    "frame_size = (640, 480) # 프레임 크기 (예: 가로 640, 세로 480)\n",
    "result_vid = cv2.VideoWriter(output_filename, fourcc, fps, frame_size) # VideoWriter 객체 생성\n",
    "result_vid.write(color_filenames)\n",
    "result_vid.release() \n",
    "\n",
    "prev_bounding_box = ...\n",
    "\n",
    "for i in range(depth_filenames):\n",
    "\n",
    "    # load Image\n",
    "    depth_image = cv2.imread(depth_filenames[i])\n",
    "    # take depth difference\n",
    "    diff = depth_image-background_depth\n",
    "\n",
    "    ## process bounding box - copied from 'practice1.ipynb'\n",
    "    # Normalize the difference image to range [0, 255]\n",
    "    normalized_diff = cv2.normalize(np.abs(diff), None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    # Binarize\n",
    "    _, im_th = cv2.threshold(normalized_diff, 30, 255, cv2.THRESH_BINARY)\n",
    "    # Taking a matrix of size 5 as the kernel ; gernerate 5*5 array filled with 1\n",
    "    kernel = np.ones((5, 5), np.uint8) \n",
    "\n",
    "    img_erosion = cv2.erode(im_th, kernel, iterations=3) \n",
    "    img_dilation = cv2.dilate(im_th, kernel, iterations=3) \n",
    "    # Get all group of pixels using cv.connectedComponentsWithStats()\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(img_erosion)\n",
    "\n",
    "    # Step 4: Filter out small areas and draw bounding boxes\n",
    "    threshold = 100\n",
    "    # Iterate through stats to filter out small areas and draw bounding boxes\n",
    "    for i in range(1, num_labels): # num_labels : connected number of labels\n",
    "        area = stats[i, cv2.CC_STAT_AREA] # stats[i, cv2.CC_STAT_AREA]is the number of pixels(area) of ith label(group)\n",
    "        if area > threshold:\n",
    "            x, y, w, h = stats[i, cv2.CC_STAT_LEFT], stats[i, cv2.CC_STAT_TOP], stats[i, cv2.CC_STAT_WIDTH], stats[i, cv2.CC_STAT_HEIGHT]\n",
    "            cv2.rectangle(c2, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Draw bounding box on color image\n",
    "\n",
    "    # Display the result\n",
    "    plt.imshow(cv2.cvtColor(c2, cv2.COLOR_BGR2RGB)) # Convert BGR to RGB for proper display with matplotlib\n",
    "    plt.show()\n",
    "\n",
    "    result_vid.write(image)\n",
    "\n",
    "result_vid.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the bounding box i/u ; later"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenCV-master-py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
